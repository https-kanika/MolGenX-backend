{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68b3d9-5301-40de-8e90-70f77e270821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131690/480774947.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA L4\n",
      "Loading ChEMBL data from ./data/chembl.mini_cleaned.smi...\n",
      "Loaded 171548 molecules from ChEMBL\n",
      "Creating new vocabulary...\n",
      "Created vocabulary with 33 characters\n",
      "Vocabulary saved to chembl_vocabulary.json\n",
      "Vocabulary size: 33\n",
      "Maximum SMILES length: 100\n",
      "Converting SMILES to sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 171548/171548 [00:01<00:00, 132381.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 171548 valid sequences\n",
      "Loading pretrained model from rnn_model.pth...\n",
      "Error loading weights: Error(s) in loading state_dict for RNNGenerator:\n",
      "\tsize mismatch for embedding.weight: copying a param with shape torch.Size([35, 128]) from checkpoint, the shape in current model is torch.Size([33, 128]).\n",
      "\tsize mismatch for fc.weight: copying a param with shape torch.Size([35, 256]) from checkpoint, the shape in current model is torch.Size([33, 256]).\n",
      "\tsize mismatch for fc.bias: copying a param with shape torch.Size([35]) from checkpoint, the shape in current model is torch.Size([33]).\n",
      "Starting from scratch instead.\n",
      "Starting training for 20 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|                                                                       | 0/1341 [00:00<?, ?it/s]/tmp/ipykernel_131690/480774947.py:182: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "Epoch 1/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.788257, Time: 7.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 0.500666, Time: 7.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 0.442593, Time: 7.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 180.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 0.410127, Time: 7.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 0.389988, Time: 7.51s\n",
      "Checkpoint saved to rnn_model_chembl_ep5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 178.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 0.376991, Time: 7.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 0.367904, Time: 7.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 0.361091, Time: 7.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 0.355735, Time: 7.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 177.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 0.351370, Time: 7.58s\n",
      "Checkpoint saved to rnn_model_chembl_ep10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 0.347810, Time: 7.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 180.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 0.344587, Time: 7.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 0.341938, Time: 7.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 0.339504, Time: 7.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 0.337378, Time: 7.43s\n",
      "Checkpoint saved to rnn_model_chembl_ep15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 180.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 0.335381, Time: 7.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 180.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 0.333587, Time: 7.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 179.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 0.331896, Time: 7.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 181.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 0.330495, Time: 7.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████████████████████████████████████████████████████| 1341/1341 [00:07<00:00, 180.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 0.328932, Time: 7.47s\n",
      "Checkpoint saved to rnn_model_chembl_ep20.pth\n",
      "Final model saved to rnn_model_chembl.pth\n",
      "\n",
      "Generating and validating molecules:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating molecules:   0%|                                                               | 0/50 [00:00<?, ?it/s][15:56:38] SMILES Parse Error: unclosed ring for input: 'Cc1cccc2cc3n(c12)OCC(C)(C)C(C)(C)C32'\n",
      "[15:56:38] Explicit valence for atom # 13 C, 5, is greater than permitted\n",
      "Generating molecules:  18%|█████████▉                                             | 9/50 [00:00<00:01, 26.13it/s][15:56:39] Can't kekulize mol.  Unkekulized atoms: 5 7 8 9 10 11 12\n",
      "Generating molecules:  26%|██████████████                                        | 13/50 [00:00<00:01, 25.96it/s][15:56:39] SMILES Parse Error: unclosed ring for input: 'CC(C)CC(N)C(=O)NC(CC(C)C)C(O)C1CCC(C(O)C2C3CCC4CCC3(C)C2CCC2(C)C3CCC12C)C(C)C'\n",
      "Generating molecules:  32%|█████████████████▎                                    | 16/50 [00:00<00:01, 25.35it/s][15:56:39] Can't kekulize mol.  Unkekulized atoms: 10 11 12 13 15 27 28\n",
      "Generating molecules:  68%|████████████████████████████████████▋                 | 34/50 [00:01<00:00, 26.24it/s][15:56:40] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5 6 16 17 18\n",
      "Generating molecules:  94%|██████████████████████████████████████████████████▊   | 47/50 [00:01<00:00, 24.59it/s][15:56:40] Can't kekulize mol.  Unkekulized atoms: 6 24 25 26 27 28 29\n",
      "Generating molecules: 100%|██████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation Results:\n",
      "  Total generated: 50\n",
      "  Valid molecules: 43 (86.0%)\n",
      "  Invalid molecules: 7 (14.0%)\n",
      "\n",
      "Valid molecule examples:\n",
      "  1. CCOC(=O)c1c(O)c(Cc2ccc(C(=O)O)cc2)c(=O)c(C)c(C)c1O\n",
      "  2. CC(C)(C)c1ccc(C=CC(=O)c2ccc(C(=O)O)cc2C)cc1\n",
      "  3. Cc1cc(C)c(C(=O)N=c2[nH]nc(C(F)(F)F)nc2C)cc1F\n",
      "  4. CC(=O)Nc1cc(S(=O)(=O)N2CCCCC2)c(F)cc1Cl\n",
      "  5. COc1ccccc1C(=O)NCCc1nc(-c2ccc(C)cc2)ccc1Cl\n",
      "\n",
      "Invalid molecule examples:\n",
      "  1. Cc1cccc2cc3n(c12)OCC(C)(C)C(C)(C)C32\n",
      "  2. Cc1cccc(CC2=NC(C)(C)C2=C(Cl)=C(C#N)(C2CC2)C(C)C)c1\n",
      "  3. COC(O)=c1n[nH]c2ccccc12\n",
      "  4. CC(C)CC(N)C(=O)NC(CC(C)C)C(O)C1CCC(C(O)C2C3CCC4CCC3(C)C2CCC2(C)C3CCC12C)C(C)C\n",
      "  5. COc1ccc(-n2c(COc3ccc(C)c4[nH]c(=NCc5ccccc5)[nH]cc34)sc2)cc1\n",
      "Generated molecules saved to generated_molecules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from RnnClass import RNNGenerator\n",
    "from utils import return_vocabulary\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from rdkit import Chem\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_amp = True  # Automatic Mixed Precision for L4\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Configuration\n",
    "PRETRAINED_MODEL = \"rnn_model.pth\" \n",
    "CHEMBL_DATA_PATH = './data/chembl.mini_cleaned.smi'  \n",
    "OUTPUT_MODEL_PATH = \"rnn_model_chembl.pth\"\n",
    "BATCH_SIZE = 128  \n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 20\n",
    "\n",
    "def validate_smiles(smiles):\n",
    "    \"\"\"Check if a SMILES string is valid using RDKit\"\"\"\n",
    "    if not smiles or len(smiles) < 3:\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def create_new_vocabulary(smiles_list, min_freq=2):\n",
    "    \"\"\"Create a new vocabulary from SMILES strings\"\"\"\n",
    "    print(\"Creating new vocabulary...\")\n",
    "    char_counts = Counter()\n",
    "    for smiles in smiles_list:\n",
    "        for char in smiles:\n",
    "            char_counts[char] += 1\n",
    "    \n",
    "    common_chars = {char for char, count in char_counts.items() if count >= min_freq}\n",
    "    all_chars = ['<PAD>'] + sorted(list(common_chars))\n",
    "    \n",
    "    char_to_idx = {char: idx for idx, char in enumerate(all_chars)}\n",
    "    idx_to_char = {idx: char for idx, char in enumerate(all_chars)}\n",
    "    \n",
    "    print(f\"Created vocabulary with {len(char_to_idx)} characters\")\n",
    "    return char_to_idx, idx_to_char\n",
    "\n",
    "def save_vocabulary(char_to_idx, idx_to_char, filename=\"chembl_vocabulary.json\"):\n",
    "    \"\"\"Save vocabulary to JSON file\"\"\"\n",
    "    vocab_data = {\n",
    "        \"char_to_idx\": char_to_idx,\n",
    "        \"idx_to_char\": {int(k): v for k, v in idx_to_char.items()}  \n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(vocab_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Vocabulary saved to {filename}\")\n",
    "\n",
    "print(f\"Loading ChEMBL data from {CHEMBL_DATA_PATH}...\")\n",
    "with open(CHEMBL_DATA_PATH, 'r') as f:\n",
    "    chembl_smiles = [line.strip() for line in f if line.strip()]\n",
    "print(f\"Loaded {len(chembl_smiles)} molecules from ChEMBL\")\n",
    "\n",
    "# Option to create new vocabulary or use existing one\n",
    "create_new_vocab = True  # Set to True if you want to create a new vocabulary\n",
    "\n",
    "if create_new_vocab:\n",
    "    char_to_idx, idx_to_char = create_new_vocabulary(chembl_smiles)\n",
    "    save_vocabulary(char_to_idx, idx_to_char, \"chembl_vocabulary.json\")\n",
    "else:\n",
    "    print(\"Loading vocabulary...\")\n",
    "    char_to_idx, idx_to_char = return_vocabulary(\"../cleaned_smiles.csv\")\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Calculate max length for padding\n",
    "max_length = min(100, max(len(smi) for smi in chembl_smiles))\n",
    "print(f\"Maximum SMILES length: {max_length}\")\n",
    "\n",
    "def smiles_to_sequence(smiles, max_len):\n",
    "    \"\"\"Convert SMILES to padded sequence with exact length\"\"\"\n",
    "    seq = [char_to_idx.get(char, 0) for char in smiles if char in char_to_idx]\n",
    "    \n",
    "    # Truncate if too long\n",
    "    if len(seq) > max_len:\n",
    "        seq = seq[:max_len]\n",
    "    # Pad if too short\n",
    "    elif len(seq) < max_len:\n",
    "        seq = seq + [0] * (max_len - len(seq))\n",
    "    \n",
    "    return seq\n",
    "\n",
    "# Convert SMILES to sequences with fixed length\n",
    "print(\"Converting SMILES to sequences...\")\n",
    "sequences = []\n",
    "for smi in tqdm(chembl_smiles):\n",
    "    try:\n",
    "        seq = smiles_to_sequence(smi, max_length)\n",
    "        if len(seq) == max_length:  \n",
    "            sequences.append(seq)\n",
    "    except Exception as e:\n",
    "        continue  \n",
    "\n",
    "sequences = np.array(sequences, dtype=np.int64)\n",
    "print(f\"Processed {len(sequences)} valid sequences\")\n",
    "train_data = torch.tensor(sequences, dtype=torch.long)\n",
    "print(f\"Loading pretrained model from {PRETRAINED_MODEL}...\")\n",
    "model = RNNGenerator(vocab_size=vocab_size, embed_dim=128, hidden_dim=256)\n",
    "\n",
    "if os.path.exists(PRETRAINED_MODEL):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(PRETRAINED_MODEL, map_location=device))\n",
    "        print(\"Pre-trained weights loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        print(\"Starting from scratch instead.\")\n",
    "else:\n",
    "    print(f\"No pretrained model found at {PRETRAINED_MODEL}\")\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    indices = torch.randperm(len(train_data))\n",
    "    shuffled_data = train_data[indices]\n",
    "    \n",
    "    for i in tqdm(range(0, len(shuffled_data), BATCH_SIZE), desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        batch = shuffled_data[i : i + BATCH_SIZE].to(device)\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "            \n",
    "        inputs, targets = batch[:, :-1], batch[:, 1:]  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.reshape(-1))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.6f}, Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = f\"rnn_model_chembl_ep{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "torch.save(model.state_dict(), OUTPUT_MODEL_PATH)\n",
    "print(f\"Final model saved to {OUTPUT_MODEL_PATH}\")\n",
    "model.eval()\n",
    "print(\"\\nGenerating and validating molecules:\")\n",
    "\n",
    "def generate_molecule(model, temperature=0.7, max_len=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        current_seq = torch.tensor([[char_to_idx['C']]], device=device)  # Start with carbon\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            output = model(current_seq)\n",
    "            next_logits = output[0, -1, :] / temperature\n",
    "            next_probs = torch.softmax(next_logits, dim=0)\n",
    "            next_char_idx = torch.multinomial(next_probs, 1)\n",
    "            \n",
    "            current_seq = torch.cat([current_seq, next_char_idx.unsqueeze(0)], dim=1)\n",
    "            \n",
    "            if next_char_idx.item() == 0:  # PAD token\n",
    "                break\n",
    "        \n",
    "        smiles = ''.join([idx_to_char[idx.item()] for idx in current_seq[0] \n",
    "                         if idx.item() > 0 and idx.item() in idx_to_char])\n",
    "        return smiles\n",
    "\n",
    "num_to_generate = 50\n",
    "valid_molecules = []\n",
    "invalid_molecules = []\n",
    "\n",
    "for i in tqdm(range(num_to_generate), desc=\"Generating molecules\"):\n",
    "    molecule = generate_molecule(model)\n",
    "    is_valid = validate_smiles(molecule)\n",
    "    \n",
    "    if is_valid:\n",
    "        valid_molecules.append(molecule)\n",
    "    else:\n",
    "        invalid_molecules.append(molecule)\n",
    "\n",
    "print(f\"\\nGeneration Results:\")\n",
    "print(f\"  Total generated: {num_to_generate}\")\n",
    "print(f\"  Valid molecules: {len(valid_molecules)} ({len(valid_molecules)/num_to_generate*100:.1f}%)\")\n",
    "print(f\"  Invalid molecules: {len(invalid_molecules)} ({len(invalid_molecules)/num_to_generate*100:.1f}%)\")\n",
    "print(\"\\nValid molecule examples:\")\n",
    "for i, mol in enumerate(valid_molecules[:5]):\n",
    "    print(f\"  {i+1}. {mol}\")\n",
    "\n",
    "print(\"\\nInvalid molecule examples:\")\n",
    "for i, mol in enumerate(invalid_molecules[:5]):\n",
    "    print(f\"  {i+1}. {mol}\")\n",
    "\n",
    "with open(\"generated_molecules.txt\", \"w\") as f:\n",
    "    f.write(\"Valid molecules:\\n\")\n",
    "    for mol in valid_molecules:\n",
    "        f.write(f\"{mol}\\n\")\n",
    "    \n",
    "    f.write(\"\\nInvalid molecules:\\n\")\n",
    "    for mol in invalid_molecules:\n",
    "        f.write(f\"{mol}\\n\")\n",
    "\n",
    "print(f\"Generated molecules saved to generated_molecules.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1377923-8c99-4323-bdcc-15059d3b07ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
